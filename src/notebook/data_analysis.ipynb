{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning \n",
    "\n",
    "Analysing the dataset's information we can see that the shared data are the trip duration (although this figure is not always given explicitly but can be calculated by having the time of departure and arrival), the starting and ending station (name or ID), the user type and the bike ID.\n",
    "\n",
    "These data are not present in all datasets: duration is not present in the newer version of CityBike NYC, in CoGo's trips data and in Divvy's data, start and end times are not present in the Austin MetroBike (it is only present the end time and the duration so we can infer that), start and end stations are not present in the Austin MetroBike and the bike id is not present in Divvy's dataset.\n",
    "\n",
    "Another information that is present in some of the dataset are the year of Birth, the gender and the station latitude and longitude. The first two data can be useful for a social analysis on the age and the gender of the user in different cities but this data are only presented in the older version of the CityBike NYC, in BluBike (through ... check) and in CoGo's dataset (randomly, in some months it is present and in others it is not, and it changes format. These data are present only through January 2020).\n",
    "\n",
    "I plot the data since 2018 since some datasets present data only from this year until 2023. \n",
    "(Note: 2018-01 Columbus not present, 2018-02 has wrong data).\n",
    "\n",
    "In the following code we report the external libraries used to analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "data_dir = 'D:\\\\unitn\\\\Bike-Inequality\\\\data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function get_missing_data calculate the percent of data that is missing print the number of infos missing for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_data(df, data_dir):\n",
    "    # Get the number of missing data points per column\n",
    "    missing_values_count = df.isnull().sum()\n",
    "\n",
    "    # How many total missing values do we have?\n",
    "    total_cells = np.prod(df.shape)\n",
    "    total_missing = missing_values_count.sum()\n",
    "    \n",
    "    if total_missing != 0:\n",
    "        print('Missing data:', missing_values_count)\n",
    "\n",
    "    # Percent of data that is missing\n",
    "    percent_missing = (total_missing/total_cells) * 100\n",
    "\n",
    "    return percent_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the duration information\n",
    "We can plot the duration of the trip using a linear scale or a logarithmic one. In the former we divide the duration into five clusters and we plot the frequency (as a percentage) of each cluster, in the latter we plot the frequency (as the number of trips) of each time duration using a log scale on the x ax.\n",
    "\n",
    "The duration can be calculated either for each month in a year or for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(df, number_to_analyse, full_path):\n",
    "    '''\n",
    "    function to get the duration of the trip for each file\n",
    "    If the file has the duration column (in seconds or in minutes) we can directly get the duration\n",
    "    Otherwise, we have to calculate the duration by subtracting the start time from the end time\n",
    "    The function takes in consideration the format of the date for each file\n",
    "    \n",
    "    Input:\n",
    "        - df: DataFrame\n",
    "        - number_to_analyse: int\n",
    "        - full_path: str\n",
    "    Output:\n",
    "        - durations: list\n",
    "    '''\n",
    "    durations = list()\n",
    "    if 'trip_duration_seconds' in df or 'trip_duration_minutes' in df:\n",
    "        \n",
    "        if 'trip_duration_seconds' in df:\n",
    "            duration = df['trip_duration_seconds']\n",
    "            durations = [time for time in duration]\n",
    "        else:\n",
    "            duration = df['trip_duration_minutes']\n",
    "            durations = [time * 60 for time in duration]\n",
    "    else:\n",
    "        \n",
    "        start = df['start_time']\n",
    "        end = df['stop_time']\n",
    "        \n",
    "        if 'NYC' in full_path:\n",
    "            if full_path[14:20] >= '202102':\n",
    "                format = \"%Y-%m-%d %H:%M:%S\"\n",
    "            else:\n",
    "                format = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "        else:\n",
    "            format = \"%Y-%m-%d %H:%M:%S\"\n",
    "        \n",
    "        for index in range(len(end)):\n",
    "            if 'Philly' in full_path or ('Chicago' in full_path and (full_path[17:23] < '202004' or '2020Q1' in full_path)):\n",
    "                month = datetime.strptime(end[index], '%Y-%m-%d %H:%M:%S').month\n",
    "                if number_to_analyse == month:\n",
    "                    time = datetime.strptime(end[index], format) - datetime.strptime(start[index], format)\n",
    "                    durations.append(time.total_seconds())\n",
    "            time = datetime.strptime(end[index], format) - datetime.strptime(start[index], format)\n",
    "            durations.append(time.total_seconds())\n",
    "        \n",
    "    durations.sort()\n",
    "    return durations\n",
    "\n",
    "def get_cluster(num):\n",
    "    '''\n",
    "    function to determine the cluster for each number\n",
    "    This function is used for the linear plot of the data to cluster the durations into 5 clusters\n",
    "    \n",
    "    Input:\n",
    "        - num: int\n",
    "        \n",
    "    Output:\n",
    "        - str\n",
    "    '''\n",
    "    if type(num) == str:\n",
    "        num = int(float(num.replace(',', '')))\n",
    "    if num < 100:\n",
    "        return \"<100\"\n",
    "    elif num < 1000:\n",
    "        return \"<1000\"\n",
    "    elif num < 10000:\n",
    "        return \"<10000\"\n",
    "    elif num < 100000:\n",
    "        return \"<100000\"\n",
    "    else:\n",
    "        return \">100000\"\n",
    "\n",
    "def get_duration_info(df, number, full_path, linear=False):\n",
    "    '''\n",
    "    function to get the duration information for each file, cluster them and plot the frequency of each cluster\n",
    "    This function calls the get_time function to get the duration of the trip for each file and then acts accordingly to the linear flag:\n",
    "    if it is True, it clusters the durations into 5 clusters, otherwise it plots the frequency of each duration using a log scale\n",
    "    \n",
    "    Input:\n",
    "        - df: DataFrame\n",
    "        - number: int\n",
    "        - full_path: str\n",
    "        - linear: bool\n",
    "        \n",
    "    Output:\n",
    "        - frequency: dict\n",
    "    '''\n",
    "    durations = get_time(df, number, full_path)\n",
    "\n",
    "    if linear:\n",
    "        # Group numbers into clusters\n",
    "        clusters = [get_cluster(num) for num in durations]\n",
    "\n",
    "        # Calculate frequency of each cluster\n",
    "        frequency = Counter(clusters)\n",
    "    else:\n",
    "        frequency = Counter(durations)\n",
    "\n",
    "    # Extract cluster names and their frequencies\n",
    "    if linear:\n",
    "        total = sum(frequency.values())\n",
    "        for key in frequency:\n",
    "            frequency[key] /= total\n",
    "    \n",
    "    return frequency\n",
    "\n",
    "def prepare_plot_log(axs, fig, frequency, number, data_dir):\n",
    "    '''\n",
    "    function to prepare the plot for the log scale\n",
    "    \n",
    "    Input:\n",
    "        - axs: list\n",
    "        - fig: Figure\n",
    "        - frequency: dict\n",
    "        - number: int\n",
    "        - data_dir: str\n",
    "    \n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    x = number // 3\n",
    "    y = number % 3\n",
    "    \n",
    "    cluster_names = list(frequency.keys())\n",
    "    cluster_frequencies = list(frequency.values())\n",
    "    \n",
    "    bin_edges = np.logspace(np.log10(cluster_names[0]), np.log10(cluster_names[-1]), num=len(cluster_names)+1)\n",
    "    bar_width = np.diff(bin_edges)\n",
    "    \n",
    "    axs[x, y].bar(bin_edges[:-1], cluster_frequencies, width=bar_width, align='center')\n",
    "    axs[x, y].set_xscale('log')\n",
    "    axs[x, y].set_yscale('log')\n",
    "\n",
    "    # Add labels and title\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Trip duration', ylabel='Frequency')\n",
    "\n",
    "    title = 'Frequency of Trip Duration for ' + data_dir\n",
    "    fig.suptitle(title)\n",
    "\n",
    "def prepare_plot_linear(axs, fig, frequency, number, data_dir):\n",
    "    '''\n",
    "    Function to prepare the plot for the linear scale\n",
    "    \n",
    "    Input:\n",
    "        - axs: list\n",
    "        - fig: Figure\n",
    "        - frequency: dict\n",
    "        - number: int\n",
    "        - data_dir: str\n",
    "    \n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    x = number // 3\n",
    "    y = number % 3\n",
    "    \n",
    "    frequency = dict(sorted(frequency.items()))\n",
    "    cluster_names = list(frequency.keys())\n",
    "    cluster_frequencies = list(frequency.values())\n",
    "    \n",
    "    axs[x, y].bar(cluster_names, cluster_frequencies, align='center')\n",
    "    \n",
    "    for index in range(len(cluster_names)):\n",
    "        axs[x, y].text(index, cluster_frequencies[index], str(round(cluster_frequencies[index], 5)), ha='center')\n",
    "\n",
    "    # Add labels and title\n",
    "    for ax in axs.flat:\n",
    "        ax.set(xlabel='Trip duration', ylabel='Frequency')\n",
    "\n",
    "    # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "    for ax in axs.flat:\n",
    "        ax.label_outer()\n",
    "    title = 'Frequency of Trip Duration for ' + data_dir\n",
    "    fig.suptitle(title)\n",
    "\n",
    "def prepare_plot(axs, fig, frequency, number, data_dir, linear=False):\n",
    "    '''\n",
    "    Function to prepare the plot for the data\n",
    "    \n",
    "    Input:\n",
    "        - axs: list\n",
    "        - fig: Figure\n",
    "        - frequency: dict\n",
    "        - number: int\n",
    "        - data_dir: str\n",
    "        - linear: bool\n",
    "        \n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    if linear:\n",
    "        prepare_plot_linear(axs, fig, frequency, number, data_dir)\n",
    "    else:\n",
    "        prepare_plot_log(axs, fig, frequency, number, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monthly duration frequency of trip\n",
    "In Austin we can observe that in 2018 and 2019 the majority of the trip durations was smaller than 1000 seconds. In particular we can note a peak around 400 seconds.Instead in 2020 and 2021 (until August) the number of trips with duration between 1000 and 10000 greatly increases. We can hypothesize that this is due to the Covid pandemic: it is possible that people start to use the bike more often in order to avoid public transports such as metro and bus.\n",
    "Since August 2021 we see a return to the previous percentages.\n",
    "\n",
    "In Columbus we note a similar trends but with some exception.\n",
    "\n",
    "In Boston, Chicago, Philly, San Francisco, NYC and Washington instead we note how the most popular trips always remain those lasting less than 1000 seconds with the exception of a few months in 2020 in Boston, Chicago and Washington."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_month(data_dir, year_flag=False, linear=False):\n",
    "    '''\n",
    "    Function to plot the trip duration frequency for each month. The function takes two flags: year_flag and linear.\n",
    "    If year_flag is True, the function plots the data for each year, otherwise it plots the data for each month.\n",
    "    If linear is True, the function clusters the data into 5 clusters, otherwise it plots the data using a log scale.\n",
    "    \n",
    "    Input:\n",
    "        - data_dir: str\n",
    "        - year_flag: bool\n",
    "        - linear: bool\n",
    "        \n",
    "    Output:\n",
    "        - frequency_dict: dict\n",
    "    '''\n",
    "\n",
    "    data_files = os.listdir(data_dir)\n",
    "    month = 0\n",
    "\n",
    "    if not year_flag:\n",
    "        fig, ax = plt.subplots(4, 3)\n",
    "    \n",
    "    if linear:\n",
    "        frequency_dict = {\n",
    "            '<100': 0,\n",
    "            '<1000': 0,\n",
    "            '<10000': 0,\n",
    "            '<100000': 0,\n",
    "            '>100000': 0\n",
    "        }\n",
    "\n",
    "    for file in data_files:\n",
    "        # read data from each file into a DataFrame\n",
    "        file_path = os.path.join(data_dir, file)\n",
    "        \n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        if 'Philly' in data_dir or ('Chicago' in file_path and file_path[18:24] < '202004') or  ('Chicago' in file_path and '2020Q1' in file_path):\n",
    "            month = (int(file[5:6]) - 1) * 3\n",
    "            for _ in range(3):\n",
    "                frequency = get_duration_info(df, month, file_path, linear)\n",
    "                if not year_flag:\n",
    "                    prepare_plot(ax, fig, frequency, month, data_dir, linear)\n",
    "                month += 1\n",
    "        else:\n",
    "            month = int(file[4:6]) - 1\n",
    "            frequency = get_duration_info(df, month, file_path, linear)\n",
    "            if not year_flag:\n",
    "                prepare_plot(ax, fig, frequency, month, data_dir, linear)\n",
    "        if linear:\n",
    "            for key in frequency:\n",
    "                frequency_dict[key] += frequency[key]\n",
    "\n",
    "    if not year_flag:\n",
    "        plt.show()\n",
    "    \n",
    "    if linear:\n",
    "        return frequency_dict\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yearly duration frequency\n",
    "In Austin and Columbus we can note that the majority of trip durations last between 100 and 1000 seconds with exception of 2020 where the trips with duration between 1000 and 10000 increases. We can also note that in 2021 also the most popular duration is the 100-1000 one but there is also a great number of trips in the 1000-10000 range.\n",
    "\n",
    "In Boston, Chicago, Philly, San Francisco and Washington we note that the most popular range is 100-1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_year(data_dir, linear=False):\n",
    "    '''\n",
    "    function to plot the data for each year\n",
    "    '''\n",
    "\n",
    "    fig, ax = plt.subplots(2, 3)\n",
    "    if linear:\n",
    "        yearly_frequency = {\n",
    "            '<100': 0,\n",
    "            '<1000': 0,\n",
    "            '<10000': 0,\n",
    "            '<100000': 0,\n",
    "            '>100000': 0\n",
    "        }\n",
    "    else:\n",
    "        yearly_frequency = dict()\n",
    "    \n",
    "    for year in os.listdir(data_dir):\n",
    "        year_path = os.path.join(data_dir, year)\n",
    "        frequency = data_for_month(year_path, year_flag=True, linear=linear)\n",
    "        for key in frequency:\n",
    "            if key in yearly_frequency:\n",
    "                yearly_frequency[key] += frequency[key]\n",
    "            else:\n",
    "                yearly_frequency[key] = frequency[key]\n",
    "        if linear:\n",
    "            total = sum(yearly_frequency.values())\n",
    "            for key in yearly_frequency:\n",
    "                yearly_frequency[key] /= total\n",
    "        \n",
    "        year = int(year) - 2018\n",
    "        prepare_plot(ax, fig, yearly_frequency, year, year_path, linear=linear)\n",
    "        frequency.clear()\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender analysis\n",
    "In general we can note that in all the cities a great majority of the bikes are used by men (around 60-80%).\n",
    "\n",
    "In Austin, Philly, San Francisco  and Washington the data is not available but we can expect the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_gender(data_dir):\n",
    "    '''\n",
    "    Function to plot the distribution of the trip between men and women\n",
    "    \n",
    "    Input:\n",
    "        - data_dir: str\n",
    "        \n",
    "    Output:\n",
    "        - None\n",
    "    '''\n",
    "    data_files = os.listdir(data_dir)\n",
    "    genders_infos = {\n",
    "        'unknown': 0,\n",
    "        'men': 0,\n",
    "        'women': 0,\n",
    "    }\n",
    "    \n",
    "    meaning_gender = {\n",
    "        '0': 'unknown',\n",
    "        '1': 'men',\n",
    "        '2': 'women',\n",
    "        'Male': 'men',\n",
    "        'Female': 'women',\n",
    "        'Unknown': 'unknown'\n",
    "    }\n",
    "\n",
    "    for year in data_files:\n",
    "        # read data from each file into a DataFrame\n",
    "        year_path = os.path.join(data_dir, year)\n",
    "        for file in os.listdir(year_path):\n",
    "            \n",
    "            file_path = os.path.join(year_path, file)\n",
    "            \n",
    "            df = pd.read_csv(file_path, dtype='object')\n",
    "            count = df['gender'].value_counts()\n",
    "            # plot the percentage of each data\n",
    "            for key in meaning_gender:\n",
    "                if key in count:\n",
    "                    genders_infos[meaning_gender[key]] += count.loc[key]\n",
    "    \n",
    "    if genders_infos['men'] != 0 or genders_infos['women'] != 0:\n",
    "        remove_zeros(genders_infos)\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.title(data_dir)\n",
    "        plt.pie(genders_infos.values(), labels=genders_infos.keys(),  autopct='%1.1f%%')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('Gender data not available in this city:', data_dir[5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Type analysis\n",
    "In Austin we can note that the majority of the rides are associated some sort of student membership like 'Student Membership' and 'U.T. Student Membership'.\n",
    "The second most used type of pass is the 'customers' one that includes 'Walk Up', '3-Day Weekender', 'Explorer' and 'Pay as you ride' even if the percentage of customers' pass is very similar to the subscriber pass one.\n",
    "\n",
    "In Boston (72%), Chicago (59.9%), NYC (67.3%), Philly (90.1%) and Washington (68.9%) the most common type is the \"subscribers\" pass.\n",
    "In Columbus the most common pass is the \"customers\" one (54.7%).\n",
    "\n",
    "In San Francisco the type of pass are very similar in fact the \"subscribers\" one has a 39.3% of popularity and the \"customers\" one as a 31.6%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_usertype(data_dir):\n",
    "    \n",
    "    data_files = os.listdir(data_dir)\n",
    "    usertypes_infos = {\n",
    "        'unknown': 0,\n",
    "        'customers': 0,\n",
    "        'subscribers': 0,\n",
    "        'students': 0,\n",
    "        'others': 0\n",
    "    }\n",
    "    \n",
    "    meaning_pass = {\n",
    "        'Indego30': 'subscribers',\n",
    "        'Indego365': 'subscribers',\n",
    "        'Walk-up': 'others',\n",
    "        'Day Pass': 'customers',\n",
    "        'IndegoFlex': 'subscribers',\n",
    "        'Walk Up': 'customers',\n",
    "        'Local365': 'subscribers',\n",
    "        'Local30': 'subscribers',\n",
    "        'Local31': 'subscribers',\n",
    "        'Local365+Guest Pass': 'subscribers',\n",
    "        'Republic Rider': 'others',\n",
    "        'Student Membership': 'students',\n",
    "        'U.T. Student Membership': 'students',\n",
    "        '3-Day Weekender': 'customers',\n",
    "        'Explorer': 'customers',\n",
    "        'Pay-as-you-ride': 'customers',\n",
    "        'Single Trip (Pay-as-you-ride)': 'customers',\n",
    "        'customers': 'customers',\n",
    "        'subscribers': 'subscribers',\n",
    "        'casual': 'customers',\n",
    "        'member': 'subscribers',\n",
    "        'Casual': 'customers',\n",
    "        'Member': 'subscribers',\n",
    "        'unknown': 'unknown'\n",
    "    }\n",
    "\n",
    "    for year in data_files:\n",
    "        # read data from each file into a DataFrame\n",
    "        year_path = os.path.join(data_dir, year)\n",
    "        \n",
    "        for file in os.listdir(year_path):\n",
    "            file_path = os.path.join(year_path, file)\n",
    "        \n",
    "            df = pd.read_csv(file_path, dtype='object')\n",
    "            count = df['usertype'].value_counts()\n",
    "            for key in meaning_pass:\n",
    "                if key in count:\n",
    "                    usertypes_infos[meaning_pass[key]] += count.loc[key]\n",
    "    \n",
    "    remove_zeros(usertypes_infos)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.title(data_dir)\n",
    "    plt.pie(usertypes_infos.values(), labels=usertypes_infos.keys(),  autopct='%1.1f%%')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(data_dir):\n",
    "    print('City:', file)\n",
    "    data_dir_city = os.path.join(data_dir, file)\n",
    "    \n",
    "    # plot date for each month\n",
    "    for year in os.listdir(data_dir_city):\n",
    "        print('Year:', year)\n",
    "        data_dir_city_year = os.path.join(data_dir_city, year)\n",
    "        data_for_month(data_dir_city_year)\n",
    "    \n",
    "    data_for_year(data_dir_city)\n",
    "    data_for_gender(data_dir_city)\n",
    "    data_for_usertype(data_dir_city)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
